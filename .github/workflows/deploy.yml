name: Deploy

on:
  push:
    branches: [main, master, dev]
  workflow_dispatch:
    inputs:
      destroy_first:
        description: 'Destroy all resources first (clean slate)'
        type: boolean
        default: false

env:
  AWS_REGION: us-east-1
  ECS_CLUSTER: sweetdream-cluster

jobs:

  # Deploy everything
  deploy-infrastructure:
    name: Deploy Infrastructure
    runs-on: ubuntu-latest
    timeout-minutes: 45
    environment: ${{ (github.ref == 'refs/heads/main' || github.ref == 'refs/heads/master') && 'production' || 'development' }}
    defaults:
      run:
        working-directory: terraform
    steps:
      - uses: actions/checkout@v4
      
      - uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}
      
      - uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: 1.6.0
      
      - name: Terraform Init
        run: terraform init
      
      - name: Check and Import Existing Resources
        continue-on-error: true
        run: |
          echo "Checking for existing resources..."
          
          # Function to check if bucket exists
          check_and_import_bucket() {
            local bucket_name=$1
            local tf_address=$2
            
            if aws s3api head-bucket --bucket "$bucket_name" 2>/dev/null; then
              echo "âœ“ Found bucket: $bucket_name"
              
              # Check if already in state
              if ! terraform state show "$tf_address" &>/dev/null; then
                echo "  Importing bucket into state..."
                terraform import "$tf_address" "$bucket_name" 2>/dev/null || echo "  Import failed or already exists"
              else
                echo "  Already in state"
              fi
              
              # Import versioning
              local versioning_address="${tf_address/aws_s3_bucket.analytics/aws_s3_bucket_versioning.analytics}"
              if ! terraform state show "$versioning_address" &>/dev/null; then
                echo "  Importing versioning..."
                terraform import "$versioning_address" "$bucket_name" 2>/dev/null || echo "  Versioning import failed"
              fi
            else
              echo "âœ— Bucket not found: $bucket_name (will be created)"
            fi
          }
          
          # Import backend analytics bucket
          check_and_import_bucket "sweetdream-analytics-backend-production" "module.backend_analytics[0].aws_s3_bucket.analytics"
          
          # Import order analytics bucket
          check_and_import_bucket "sweetdream-analytics-order-production" "module.order_analytics[0].aws_s3_bucket.analytics"
          
          echo "âœ“ Import check completed" >> $GITHUB_STEP_SUMMARY
      
      - name: Terraform Apply
        run: |
          terraform plan -out=tfplan -var="db_password=${{ secrets.DB_PASSWORD }}"
          terraform apply -auto-approve tfplan
          echo "âœ“ Infrastructure deployed" >> $GITHUB_STEP_SUMMARY

  # Build and deploy all services
  deploy-services:
    name: Deploy All Services
    needs: [deploy-infrastructure]
    if: always() && !cancelled() && needs.deploy-infrastructure.result == 'success'
    runs-on: ubuntu-latest
    environment: ${{ (github.ref == 'refs/heads/main' || github.ref == 'refs/heads/master') && 'production' || 'development' }}
    steps:
      - uses: actions/checkout@v4
      
      - uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}
      
      - uses: aws-actions/amazon-ecr-login@v2
        id: ecr
      
      - name: Get ALB URL
        id: alb
        run: |
          ALB_URL=$(aws elbv2 describe-load-balancers \
            --query 'LoadBalancers[?contains(LoadBalancerName, `sweetdream`)].DNSName' \
            --output text)
          echo "url=$ALB_URL" >> $GITHUB_OUTPUT
      
      - name: Build & Push All Images
        env:
          ECR_REGISTRY: ${{ steps.ecr.outputs.registry }}
          NEXT_PUBLIC_API_URL: http://${{ steps.alb.outputs.url }}
        run: |
          echo "Building all Docker images..."
          
          # Backend
          docker build -t $ECR_REGISTRY/sweetdream-backend:latest ./be
          docker push $ECR_REGISTRY/sweetdream-backend:latest
          echo "Backend pushed"
          
          # Frontend
          docker build --build-arg NEXT_PUBLIC_API_URL=$NEXT_PUBLIC_API_URL \
            -t $ECR_REGISTRY/sweetdream-frontend:latest ./fe
          docker push $ECR_REGISTRY/sweetdream-frontend:latest
          echo "Frontend pushed"
          
          # Order Service
          docker build -t $ECR_REGISTRY/sweetdream-order-service:latest ./order-service
          docker push $ECR_REGISTRY/sweetdream-order-service:latest
          echo "Order Service pushed"
          
          # User Service
          docker build -t $ECR_REGISTRY/sweetdream-user-service:latest ./user-service
          docker push $ECR_REGISTRY/sweetdream-user-service:latest
          echo "User Service pushed"
      
      - name: Deploy All Services to ECS
        run: |
          echo "ðŸš€ Deploying all services..."
          
          services=(
            "sweetdream-service-backend"
            "sweetdream-service-frontend"
            "sweetdream-service-order-service"
            "sweetdream-service-user-service"
          )
          
          for service in "${services[@]}"; do
            echo "Deploying: $service"
            aws ecs update-service \
              --cluster ${{ env.ECS_CLUSTER }} \
              --service $service \
              --force-new-deployment \
              --no-cli-pager || echo "Service $service not ready yet"
          done
          
          echo "All services deployed" >> $GITHUB_STEP_SUMMARY

  # Summary
  summary:
    name: Deployment Summary
    needs: [deploy-infrastructure, deploy-services]
    if: always()
    runs-on: ubuntu-latest
    steps:
      - uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}
      
      - name: Get Info
        id: info
        run: |
          ALB_URL=$(aws elbv2 describe-load-balancers \
            --query 'LoadBalancers[?contains(LoadBalancerName, `sweetdream`)].DNSName' \
            --output text)
          echo "alb_url=$ALB_URL" >> $GITHUB_OUTPUT
      
      - name: Create Summary
        run: |
          echo "## ðŸš€ Deployment Complete" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Status" >> $GITHUB_STEP_SUMMARY
          echo "- Infrastructure: ${{ needs.deploy-infrastructure.result }}" >> $GITHUB_STEP_SUMMARY
          echo "- Services: ${{ needs.deploy-services.result }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### ðŸŒ Access" >> $GITHUB_STEP_SUMMARY
          echo "- **URL**: http://${{ steps.info.outputs.alb_url }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Branch**: ${{ github.ref_name }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Commit**: \`${{ github.sha }}\`" >> $GITHUB_STEP_SUMMARY
